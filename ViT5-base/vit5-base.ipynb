{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Import Library**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:24.524599Z","iopub.status.busy":"2024-06-09T11:09:24.524110Z","iopub.status.idle":"2024-06-09T11:09:24.531079Z","shell.execute_reply":"2024-06-09T11:09:24.529922Z","shell.execute_reply.started":"2024-06-09T11:09:24.524564Z"},"trusted":true},"outputs":[],"source":["# import libs\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n","import torch\n","from torchtext.data.utils import get_tokenizer\n","from collections import Counter\n","from torchtext.vocab import vocab\n","import re\n","from datasets import Dataset, DatasetDict\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from torchtext.data.metrics import bleu_score\n","import wandb"]},{"cell_type":"markdown","metadata":{},"source":["# **Load dataset**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:24.534024Z","iopub.status.busy":"2024-06-09T11:09:24.533404Z","iopub.status.idle":"2024-06-09T11:09:24.540700Z","shell.execute_reply":"2024-06-09T11:09:24.539754Z","shell.execute_reply.started":"2024-06-09T11:09:24.533993Z"},"trusted":true},"outputs":[],"source":["train_filepaths=[\n","    r'/kaggle/input/pho-mt/train.en',\n","    r'/kaggle/input/pho-mt/train.vi'\n","]\n","dev_filepaths=[\n","    r'/kaggle/input/pho-mt/dev.en',\n","    r'/kaggle/input/pho-mt/dev.vi'\n","]\n","test_filepaths=[\n","    r'/kaggle/input/pho-mt/test.en',\n","    r'/kaggle/input/pho-mt/test.vi'\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:24.542339Z","iopub.status.busy":"2024-06-09T11:09:24.541947Z","iopub.status.idle":"2024-06-09T11:09:24.597797Z","shell.execute_reply":"2024-06-09T11:09:24.596710Z","shell.execute_reply.started":"2024-06-09T11:09:24.542304Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE=32\n","lower=True\n","SRC_LANGUAGE = 'en'\n","TGT_LANGUAGE = 'vi'\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","load_model = True\n","save_model = True"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:24.599647Z","iopub.status.busy":"2024-06-09T11:09:24.599305Z","iopub.status.idle":"2024-06-09T11:09:41.167739Z","shell.execute_reply":"2024-06-09T11:09:41.166893Z","shell.execute_reply.started":"2024-06-09T11:09:24.599619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 2977999\n","    })\n","    validation: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 18719\n","    })\n","    test: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 19151\n","    })\n","})\n"]}],"source":["# Function to load data from files\n","def load_data(en_path, vi_path):\n","    with open(en_path, encoding='utf-8') as f:\n","        en_data = f.readlines()\n","    with open(vi_path, encoding='utf-8') as f:\n","        vi_data = f.readlines()\n","    return {'en': en_data, 'vi': vi_data}\n","\n","# Load train, dev, and test data\n","train_data = load_data(train_filepaths[0], train_filepaths[1])\n","dev_data = load_data(dev_filepaths[0], dev_filepaths[1])\n","test_data = load_data(test_filepaths[0], test_filepaths[1])\n","\n","# Create DatasetDict\n","datasets = DatasetDict({\n","    'train': Dataset.from_dict(train_data),\n","    'validation': Dataset.from_dict(dev_data),\n","    'test': Dataset.from_dict(test_data)\n","})\n","print(datasets)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:41.171481Z","iopub.status.busy":"2024-06-09T11:09:41.171128Z","iopub.status.idle":"2024-06-09T11:09:42.550475Z","shell.execute_reply":"2024-06-09T11:09:42.549409Z","shell.execute_reply.started":"2024-06-09T11:09:41.171456Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 5955\n","    })\n","    validation: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 37\n","    })\n","    test: Dataset({\n","        features: ['vi', 'en'],\n","        num_rows: 19151\n","    })\n","})\n"]}],"source":["# from datasets import load_dataset\n","\n","# # Function to sample a fraction of the dataset\n","# def sample_dataset(dataset, fraction=1/500):\n","#     return dataset.train_test_split(test_size=(1 - fraction))['train']\n","\n","# # Sample train, validation, and test sets\n","# sampled_train = sample_dataset(datasets['train'])\n","# sampled_validation = sample_dataset(datasets['validation'])\n","# sampled_test = datasets['test']\n","\n","# # Combine the sampled datasets into a new DatasetDict\n","# sampled_dataset = DatasetDict({\n","#     'train': sampled_train,\n","#     'validation': sampled_validation,\n","#     'test': sampled_test\n","# })\n","\n","# # Display the sampled dataset information\n","# print(sampled_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["**Import model**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:42.552694Z","iopub.status.busy":"2024-06-09T11:09:42.551853Z","iopub.status.idle":"2024-06-09T11:09:56.993216Z","shell.execute_reply":"2024-06-09T11:09:56.992279Z","shell.execute_reply.started":"2024-06-09T11:09:42.552659Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09075dc299934621875dc3b87bfe19c8","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c2240eae0604fc782255e8c444edc17","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b1051ebca214e5c8d1c81b074e6b9fe","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9afa62aba5bb45968c2257d7020f8f1c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62b17776d35a4d18a41a20f9bb58dc7e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"840b82b2ffdd4b088f766a9934eae532","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["# Load the pretrained ViT5 model\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","model_name = \"VietAI/vit5-base\"  # replace with the actual model name if available\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:09:56.994538Z","iopub.status.busy":"2024-06-09T11:09:56.994279Z","iopub.status.idle":"2024-06-09T11:10:09.578698Z","shell.execute_reply":"2024-06-09T11:10:09.577810Z","shell.execute_reply.started":"2024-06-09T11:09:56.994517Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"885c4e551d6c4474a6d4febc8e10f036","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/5955 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b96b17b803334c84b49bcc77094dc652","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/37 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41aad5298340403bbdf13dd8cd84d570","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19151 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Preprocess the dataset\n","def preprocess_function(examples):\n","    inputs = [\"translate English to Vietnamese: \" + ex for ex in examples['en']]\n","    targets = [ex for ex in examples['vi']]\n","    model_inputs = tokenizer(inputs, max_length=64, truncation=True, padding=\"max_length\")\n","    labels = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\")\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_datasets = datasets.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:10:09.580764Z","iopub.status.busy":"2024-06-09T11:10:09.580070Z","iopub.status.idle":"2024-06-09T11:10:09.589724Z","shell.execute_reply":"2024-06-09T11:10:09.588850Z","shell.execute_reply.started":"2024-06-09T11:10:09.580726Z"},"trusted":true},"outputs":[],"source":["# Define function to collate data samples into batch tensors\n","def generate_batch(batch):\n","    src_batch = [sample['input_ids'] for sample in batch]\n","    tgt_batch = [sample['labels'] for sample in batch]\n","    src_batch = pad_sequence(src_batch, padding_value=1)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=1)\n","    return {'input_ids': src_batch, 'labels': tgt_batch}\n","\n","# Create DataLoaders\n","train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n","val_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n","test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)"]},{"cell_type":"markdown","metadata":{},"source":["# **Training**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:10:09.591328Z","iopub.status.busy":"2024-06-09T11:10:09.591015Z","iopub.status.idle":"2024-06-09T11:10:09.657561Z","shell.execute_reply":"2024-06-09T11:10:09.656820Z","shell.execute_reply.started":"2024-06-09T11:10:09.591303Z"},"trusted":true},"outputs":[],"source":["# Data collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# Training arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"steps\",\n","    eval_steps = 1000,\n","    save_strategy=\"steps\", # Change to \"steps\" to save after a certain number of steps\n","    save_steps=1000, # Save after every 1000 steps\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    weight_decay=0.01,\n","    save_total_limit=1,\n","    num_train_epochs=1,\n","    predict_with_generate=True,\n","    fp16 = True\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:10:09.659399Z","iopub.status.busy":"2024-06-09T11:10:09.659017Z","iopub.status.idle":"2024-06-09T11:12:20.272163Z","shell.execute_reply":"2024-06-09T11:12:20.271208Z","shell.execute_reply.started":"2024-06-09T11:10:09.659367Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvuduchung3103\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240609_111012-lfuu7e2n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/vuduchung3103/MT/runs/lfuu7e2n' target=\"_blank\">glorious-pond-7</a></strong> to <a href='https://wandb.ai/vuduchung3103/MT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/vuduchung3103/MT' target=\"_blank\">https://wandb.ai/vuduchung3103/MT</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/vuduchung3103/MT/runs/lfuu7e2n' target=\"_blank\">https://wandb.ai/vuduchung3103/MT/runs/lfuu7e2n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [94/94 01:45, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=94, training_loss=3.6187279883851398, metrics={'train_runtime': 110.3888, 'train_samples_per_second': 53.946, 'train_steps_per_second': 0.852, 'total_flos': 453293029785600.0, 'train_loss': 3.6187279883851398, 'epoch': 1.0})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator\n",")\n","wandb.login(key = \"657caa4a9ec74a7425c69683dc166f64282e7513\")\n","wandb.init(project = \"MT\")\n","# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T11:12:20.273518Z","iopub.status.busy":"2024-06-09T11:12:20.273236Z","iopub.status.idle":"2024-06-09T11:12:21.657778Z","shell.execute_reply":"2024-06-09T11:12:21.656691Z","shell.execute_reply.started":"2024-06-09T11:12:20.273493Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved\n"]}],"source":["# Save the model\n","trainer.save_model(\"./fine-tuned-vit5\")\n","print(\"Model saved\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5165397,"sourceId":8627588,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
